#!/usr/bin/env python3
"""
YOLOv11-Pose Training Script for Dial Gauge Pointer Detection
Trains on bbox + 2 keypoints with visualization
"""
import os
import sys
import torch
import yaml
import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # éGUIå¾Œç«¯

# Patch torch.load BEFORE importing ultralytics
original_torch_load = torch.load

def patched_torch_load(*args, **kwargs):
    """Patched torch.load that sets weights_only=False"""
    kwargs['weights_only'] = False
    return original_torch_load(*args, **kwargs)

torch.load = patched_torch_load

try:
    from ultralytics import YOLO
    from ultralytics.utils.plotting import Annotator, colors
    print("âœ… Successfully imported YOLO from ultralytics")
except ImportError as e:
    print(f"âŒ Error importing YOLO: {e}")
    print("Make sure you have installed ultralytics:")
    print("pip install ultralytics")
    sys.exit(1)


class TrainingVisualizer:
    """è¨“ç·´éç¨‹å¯è¦–åŒ–å™¨"""
    
    def __init__(self, save_dir):
        self.save_dir = Path(save_dir)
        self.vis_dir = self.save_dir / 'visualizations'
        self.vis_dir.mkdir(parents=True, exist_ok=True)
        
        self.metrics_history = {
            'box_loss': [],
            'pose_loss': [],
            'kobj_loss': [],
            'cls_loss': [],
            'dfl_loss': [],
            'mAP50': [],
            'mAP50-95': [],
        }
        
        print(f"ğŸ“Š Visualization directory: {self.vis_dir}")
    
    def save_training_batch_visualization(self, model, dataset_path, epoch, num_samples=4):
        """å¯è¦–åŒ–è¨“ç·´æ‰¹æ¬¡çš„é æ¸¬çµæœ"""
        try:
            dataset_path = Path(dataset_path)
            val_images_dir = dataset_path / 'valid' / 'images'
            val_labels_dir = dataset_path / 'valid' / 'labels'
            
            if not val_images_dir.exists():
                return
            
            # éš¨æ©Ÿé¸æ“‡åœ–ç‰‡
            image_files = list(val_images_dir.glob('*'))[:num_samples]
            
            fig, axes = plt.subplots(2, 2, figsize=(16, 16))
            axes = axes.flatten()
            
            for idx, img_path in enumerate(image_files):
                if idx >= 4:
                    break
                
                # è®€å–åœ–ç‰‡
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                # åŸ·è¡Œé æ¸¬
                results = model.predict(img_path, verbose=False, save=False)
                
                if len(results) > 0:
                    result = results[0]
                    
                    # ç¹ªè£½çµæœ
                    annotated = img_rgb.copy()
                    
                    # ç¹ªè£½ bbox
                    if result.boxes is not None and len(result.boxes) > 0:
                        for box in result.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            
                            # ç¹ªè£½æ¡†
                            cv2.rectangle(annotated, 
                                        (int(x1), int(y1)), 
                                        (int(x2), int(y2)), 
                                        (0, 255, 0), 2)
                            
                            # ç¹ªè£½ç½®ä¿¡åº¦
                            label = f'{conf:.2f}'
                            cv2.putText(annotated, label, 
                                      (int(x1), int(y1)-10),
                                      cv2.FONT_HERSHEY_SIMPLEX, 
                                      0.5, (0, 255, 0), 2)
                    
                    # ç¹ªè£½é—œéµé»
                    if result.keypoints is not None and len(result.keypoints) > 0:
                        for kpts in result.keypoints:
                            kpts_data = kpts.xy[0].cpu().numpy()  # [num_kpts, 2]
                            
                            if len(kpts_data) >= 2:
                                # èµ·é» (ç¶ è‰²)
                                start = kpts_data[0]
                                cv2.circle(annotated, 
                                         (int(start[0]), int(start[1])), 
                                         8, (0, 255, 0), -1)
                                cv2.circle(annotated, 
                                         (int(start[0]), int(start[1])), 
                                         10, (0, 255, 0), 2)
                                
                                # çµ‚é» (è—è‰²)
                                end = kpts_data[1]
                                cv2.circle(annotated, 
                                         (int(end[0]), int(end[1])), 
                                         8, (255, 0, 0), -1)
                                cv2.circle(annotated, 
                                         (int(end[0]), int(end[1])), 
                                         10, (255, 0, 0), 2)
                                
                                # é€£æ¥ç·š (é»ƒè‰²)
                                cv2.line(annotated,
                                       (int(start[0]), int(start[1])),
                                       (int(end[0]), int(end[1])),
                                       (255, 255, 0), 3)
                
                # é¡¯ç¤ºåœ¨å­åœ–
                axes[idx].imshow(annotated)
                axes[idx].set_title(f'Epoch {epoch} - {img_path.name}')
                axes[idx].axis('off')
            
            # ä¿å­˜åœ–ç‰‡
            plt.tight_layout()
            save_path = self.vis_dir / f'epoch_{epoch:03d}_predictions.jpg'
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
            plt.close()
            
            print(f"  ğŸ“¸ Saved visualization: {save_path.name}")
            
        except Exception as e:
            print(f"  âš ï¸  Visualization error: {e}")
    
    def plot_metrics(self, metrics_csv):
        """ç¹ªè£½è¨“ç·´æŒ‡æ¨™æ›²ç·š"""
        try:
            if not metrics_csv.exists():
                return
            
            import pandas as pd
            df = pd.read_csv(metrics_csv)
            
            # å‰µå»º2x2å­åœ–
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            
            # Loss æ›²ç·š
            ax = axes[0, 0]
            if 'train/box_loss' in df.columns:
                ax.plot(df['epoch'], df['train/box_loss'], label='Box Loss', linewidth=2)
            if 'train/pose_loss' in df.columns:
                ax.plot(df['epoch'], df['train/pose_loss'], label='Pose Loss', linewidth=2)
            if 'train/kobj_loss' in df.columns:
                ax.plot(df['epoch'], df['train/kobj_loss'], label='Keypoint Obj Loss', linewidth=2)
            if 'train/cls_loss' in df.columns:
                ax.plot(df['epoch'], df['train/cls_loss'], label='Cls Loss', linewidth=2)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.set_title('Training Losses')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # mAP æ›²ç·š
            ax = axes[0, 1]
            if 'metrics/mAP50(B)' in df.columns:
                ax.plot(df['epoch'], df['metrics/mAP50(B)'], 
                       label='mAP50 (Box)', linewidth=2, marker='o')
            if 'metrics/mAP50-95(B)' in df.columns:
                ax.plot(df['epoch'], df['metrics/mAP50-95(B)'], 
                       label='mAP50-95 (Box)', linewidth=2, marker='s')
            if 'metrics/mAP50(P)' in df.columns:
                ax.plot(df['epoch'], df['metrics/mAP50(P)'], 
                       label='mAP50 (Pose)', linewidth=2, marker='^')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('mAP')
            ax.set_title('Validation mAP')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # å­¸ç¿’ç‡æ›²ç·š
            ax = axes[1, 0]
            if 'lr/pg0' in df.columns:
                ax.plot(df['epoch'], df['lr/pg0'], label='LR pg0', linewidth=2)
            if 'lr/pg1' in df.columns:
                ax.plot(df['epoch'], df['lr/pg1'], label='LR pg1', linewidth=2)
            if 'lr/pg2' in df.columns:
                ax.plot(df['epoch'], df['lr/pg2'], label='LR pg2', linewidth=2)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Learning Rate')
            ax.set_title('Learning Rate Schedule')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # Precision & Recall
            ax = axes[1, 1]
            if 'metrics/precision(B)' in df.columns:
                ax.plot(df['epoch'], df['metrics/precision(B)'], 
                       label='Precision (Box)', linewidth=2)
            if 'metrics/recall(B)' in df.columns:
                ax.plot(df['epoch'], df['metrics/recall(B)'], 
                       label='Recall (Box)', linewidth=2)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Score')
            ax.set_title('Precision & Recall')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            save_path = self.vis_dir / 'training_metrics.jpg'
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"  ğŸ“ˆ Saved metrics plot: {save_path.name}")
            
        except Exception as e:
            print(f"  âš ï¸  Metrics plotting error: {e}")


def verify_pose_labels(dataset_path):
    """é©—è­‰ pose æ¨™è¨»æ–‡ä»¶"""
    print("\n" + "="*60)
    print("Verifying Pose Label Files")
    print("="*60)
    
    dataset_path = Path(dataset_path)
    
    for split in ['train', 'valid']:
        labels_dir = dataset_path / split / 'labels'
        
        if not labels_dir.exists():
            print(f"âŒ {split} labels directory not found")
            return False
        
        # æ£€æŸ¥æ‰€æœ‰ .txt æ–‡ä»¶ï¼ˆä¸å†ä¸“é—¨æ‰¾ _pose.txtï¼‰
        label_files = list(labels_dir.glob('*.txt'))
        
        if len(label_files) == 0:
            print(f"âŒ No label files found in {split}/labels")
            return False
        
        print(f"âœ… {split}: Found {len(label_files)} label files")
        
        # æ£€æŸ¥æ ¼å¼ - éªŒè¯æ˜¯å¦ä¸º pose æ ¼å¼ï¼ˆ11åˆ—ï¼‰
        valid_pose_count = 0
        invalid_count = 0
        
        for label_file in label_files[:5]:  # æ£€æŸ¥å‰5ä¸ª
            with open(label_file, 'r') as f:
                first_line = f.readline().strip()
                if first_line:
                    parts = first_line.split()
                    
                    if len(parts) == 11:
                        valid_pose_count += 1
                    else:
                        invalid_count += 1
                        print(f"   âš ï¸  {label_file.name}: {len(parts)} columns (expected 11)")
        
        if invalid_count > 0:
            print(f"   âŒ Found {invalid_count} invalid format files")
            return False
        
        print(f"   âœ… Format verified: 11 columns (pose format)")
    
    return True


def create_pose_dataset_yaml(dataset_path, output_yaml):
    """å‰µå»º YOLOv11 pose å°ˆç”¨çš„ dataset.yaml"""
    
    dataset_path = Path(dataset_path)
    
    train_images = len(list((dataset_path / 'train' / 'images').glob('*')))
    valid_images = len(list((dataset_path / 'valid' / 'images').glob('*')))
    train_pose_labels = len(list((dataset_path / 'train' / 'labels').glob('*_pose.txt')))
    valid_pose_labels = len(list((dataset_path / 'valid' / 'labels').glob('*_pose.txt')))
    
    config = {
        'path': str(dataset_path.absolute()),
        'train': 'train/images',
        'val': 'valid/images',
        'nc': 1,
        'names': ['pointer'],
        'kpt_shape': [2, 3],  # 2 keypoints, 3 dimensions each (x, y, visibility)
    }
    
    with open(output_yaml, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, sort_keys=False)
    
    print("\n" + "="*60)
    print("Dataset Configuration")
    print("="*60)
    print(f"Path: {dataset_path}")
    print(f"Train images: {train_images} (pose labels: {train_pose_labels})")
    print(f"Valid images: {valid_images} (pose labels: {valid_pose_labels})")
    print(f"Classes: 1 (pointer)")
    print(f"Keypoints: 2 (start, end)")
    print(f"Config saved: {output_yaml}")
    
    return output_yaml


def train_yolov11_pose():
    """è¨“ç·´ YOLOv11-pose æ¨¡å‹"""
    
    dataset_path = Path("/home/itemhsu/amtk/gauge/yolo_dataset")
    dataset_yaml = dataset_path / "dataset_pose.yaml"
    
    # é©—è­‰ pose æ¨™è¨»
    if not verify_pose_labels(dataset_path):
        print("\nâŒ Pose label verification failed")
        print("Please run: python batch_generate_pose_labels.py")
        return False
    
    # å‰µå»º dataset.yaml
    create_pose_dataset_yaml(dataset_path, dataset_yaml)
    
    # è¨“ç·´é…ç½®
    config = {
        'data': str(dataset_yaml),
        'epochs': 100,
        'imgsz': 960,
        'batch': 16,
        
        # å­¸ç¿’ç‡
        'lr0': 0.01,
        'lrf': 0.01,
        'momentum': 0.937,
        'weight_decay': 0.0005,
        
        # Warmup
        'warmup_epochs': 3,
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.1,
        
        # Loss æ¬Šé‡
        'box': 7.5,
        'cls': 0.5,
        'dfl': 1.5,
        'pose': 12.0,      # é«˜æ¬Šé‡ç¢ºä¿é—œéµé»æº–ç¢º
        'kobj': 2.0,       # é—œéµé»ç½®ä¿¡åº¦
        
        # æ•¸æ“šå¢å¼·ï¼ˆé—œé–‰ç¿»è½‰ä»¥ä¿æŒæ–¹å‘æ€§ï¼‰
        'fliplr': 0.0,
        'flipud': 0.0,
        'degrees': 0.0,    # ä¸æ—‹è½‰
        'translate': 0.1,
        'scale': 0.5,
        'shear': 0.0,
        'perspective': 0.0,
        'mosaic': 1.0,
        
        # å…¶ä»–è¨­ç½®
        'val': True,
        'plots': True,
        'save': True,
        'save_period': 5,   # æ¯5å€‹epochä¿å­˜ä¸€æ¬¡
        'device': '',
        'workers': 8,
        'project': 'runs/pose',
        'name': 'yolov11_pointer_pose',
        'exist_ok': False,
        'optimizer': 'auto',
        'verbose': True,
        'seed': 0,
        'deterministic': True,
        'amp': True,
        'close_mosaic': 10,
    }
    
    try:
        print("\n" + "="*60)
        print("Initializing YOLOv11-Pose Model")
        print("="*60)
        
        # å˜—è©¦åŠ è¼‰ YOLOv11-pose æ¨¡å‹
        model_variants = [
            'yolo11s-pose.pt',
        ]
        
        model = None
        loaded_variant = None
        
        for variant in model_variants:
            try:
                print(f"Trying to load {variant}...")
                model = YOLO(variant)
                loaded_variant = variant
                print(f"âœ… Successfully loaded {variant}")
                break
            except Exception as e:
                print(f"âš ï¸  {variant} not available: {str(e)[:80]}")
                continue
        
        if model is None:
            print("\nğŸ“¥ Downloading YOLOv11n-pose...")
            try:
                model = YOLO('yolo11n-pose.pt')
                loaded_variant = 'yolo11n-pose.pt'
                print("âœ… Downloaded yolo11n-pose.pt")
            except:
                print("ğŸ“¥ Trying YOLOv8n-pose as fallback...")
                model = YOLO('yolov8n-pose.pt')
                loaded_variant = 'yolov8n-pose.pt'
                print("âœ… Downloaded yolov8n-pose.pt")
        
        print("\n" + "="*60)
        print("Training Configuration")
        print("="*60)
        print(f"Model: {loaded_variant}")
        print(f"Dataset: {dataset_yaml}")
        print(f"Epochs: {config['epochs']}")
        print(f"Batch size: {config['batch']}")
        print(f"Image size: {config['imgsz']}")
        print(f"Pose loss weight: {config['pose']}")
        print(f"Keypoint obj weight: {config['kobj']}")
        print(f"Augmentation: fliplr={config['fliplr']}, flipud={config['flipud']}")
        print("="*60)
        
        # å‰µå»ºå¯è¦–åŒ–å™¨
        save_dir = Path('runs/pose/yolov11_pointer_pose')
        visualizer = TrainingVisualizer(save_dir)
        
        # é–‹å§‹è¨“ç·´
        print("\nğŸš€ Starting training...\n")
        
        # æ·»åŠ å›èª¿å‡½æ•¸é€²è¡Œå¯è¦–åŒ–
        def on_train_epoch_end(trainer):
            """æ¯å€‹ epoch çµæŸæ™‚çš„å›èª¿"""
            epoch = trainer.epoch
            
            # æ¯5å€‹epochå¯è¦–åŒ–ä¸€æ¬¡
            if epoch % 5 == 0 or epoch == trainer.epochs - 1:
                print(f"\nğŸ“Š Generating visualizations for epoch {epoch}...")
                visualizer.save_training_batch_visualization(
                    trainer.model, 
                    dataset_path, 
                    epoch
                )
        
        # è¨“ç·´æ¨¡å‹
        results = model.train(**config)
        
        # è¨“ç·´å®Œæˆå¾Œç¹ªè£½æŒ‡æ¨™
        print("\nğŸ“ˆ Generating final metrics plots...")
        results_dir = Path(results.save_dir)
        metrics_csv = results_dir / 'results.csv'
        
        if metrics_csv.exists():
            visualizer.plot_metrics(metrics_csv)
        
        # åœ¨é©—è­‰é›†ä¸Šå¯è¦–åŒ–æœ€çµ‚çµæœ
        print("\nğŸ¯ Generating final predictions visualization...")
        best_model = YOLO(results_dir / 'weights' / 'best.pt')
        visualizer.save_training_batch_visualization(
            best_model, 
            dataset_path, 
            'final',
            num_samples=8
        )
        
        print("\n" + "="*60)
        print("âœ… Training completed successfully!")
        print("="*60)
        print(f"ğŸ“ Results directory: {results.save_dir}")
        print(f"ğŸ† Best weights: {results.save_dir}/weights/best.pt")
        print(f"ğŸ“ Last weights: {results.save_dir}/weights/last.pt")
        print(f"ğŸ“Š Visualizations: {visualizer.vis_dir}")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•¸"""
    print("="*60)
    print("YOLOv11-Pose Training for Dial Gauge Pointer Detection")
    print("Training: BBox + 2 Keypoints (start, end)")
    print("With Training Visualization")
    print("="*60)
    
    dataset_path = Path("/home/itemhsu/amtk/gauge/yolo_dataset")
    
    if not dataset_path.exists():
        print(f"âŒ Error: Dataset not found at {dataset_path}")
        return
    
    # æª¢æŸ¥æ•¸æ“šé›†çµæ§‹
    required_dirs = ['train/images', 'train/labels', 'valid/images', 'valid/labels']
    missing_dirs = [d for d in required_dirs 
                   if not (dataset_path / d).exists()]
    
    if missing_dirs:
        print("âŒ Error: Required directories not found:")
        for d in missing_dirs:
            print(f"   - {d}")
        return
    
    print("âœ… Dataset structure verified")
    
    # çµ±è¨ˆæ•¸æ“š
    train_images = len(list((dataset_path / 'train/images').glob('*')))
    valid_images = len(list((dataset_path / 'valid/images').glob('*')))
    train_labels = len(list((dataset_path / 'train/labels').glob('*.txt')))
    valid_labels = len(list((dataset_path / 'valid/labels').glob('*.txt')))
    
    print(f"\nğŸ“Š Dataset Statistics:")
    print(f"  Training: {train_images} images, {train_labels} labels")
    print(f"  Validation: {valid_images} images, {valid_labels} labels")
    
    if train_labels == 0:
        print("\nâŒ No labels found!")
        print("Run: python batch_generate_pose_labels.py")
        return
    
    # æª¢æŸ¥ç¬¬ä¸€å€‹æ¨™è¨»æ–‡ä»¶çš„æ ¼å¼
    sample_label = list((dataset_path / 'train/labels').glob('*.txt'))[0]
    with open(sample_label, 'r') as f:
        first_line = f.readline().strip()
        if first_line:
            parts = first_line.split()
            if len(parts) != 11:
                print(f"\nâŒ æ¨™è¨»æ ¼å¼éŒ¯èª¤ï¼")
                print(f"  æœŸæœ›: 11åˆ— (poseæ ¼å¼)")
                print(f"  å¯¦éš›: {len(parts)}åˆ—")
                print(f"  ç¤ºä¾‹: {sample_label.name}")
                return
            else:
                print(f"  âœ… æ¨™è¨»æ ¼å¼é©—è­‰é€šé (11åˆ— poseæ ¼å¼)")
    
    # é–‹å§‹è¨“ç·´
    success = train_yolov11_pose()
    
    if success:
        print("\n" + "="*60)
        print("ğŸ‰ Training completed successfully!")
        print("="*60)
        print("\nğŸ“‚ Output files:")
        print("  - runs/pose/yolov11_pointer_pose/weights/best.pt")
        print("  - runs/pose/yolov11_pointer_pose/weights/last.pt")
        print("  - runs/pose/yolov11_pointer_pose/visualizations/*.jpg")
        print("\nğŸ” To use the trained model:")
        print("  from ultralytics import YOLO")
        print("  model = YOLO('runs/pose/yolov11_pointer_pose/weights/best.pt')")
        print("  results = model.predict('test_image.jpg')")
        print("="*60)


if __name__ == "__main__":
    main()
